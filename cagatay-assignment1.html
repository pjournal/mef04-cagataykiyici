---


---

<h1 id="hello-folks">Hello Folks!</h1>
<p>My  undergraduate degree is from ITÜ Management Engineering, a multi-disciplinary program, an odd mixture of business, economics, law and a pinch of engineering. Ater 6 years of work experience I had an MBA from Manchester Business School. Now I’m excited to go back to school 15 years after my last class in 2005. Although I have always been at the data and analytical side of business in my career, this will be the most technical degree I will get.</p>
<p>I’m a consultant with 20+ years of experience on a wide range of “digital” spectrum; marketing, advertising, analytics, digital platforms &amp; CX. Throughout my career, I have worked on different but complementary contexts including digital media, portals, advertising agencies, consulting, start-ups and marketing research. During my last 12 years as a consultant, especially due to my long term collaboration with Wunderman Thompson, I had the opportunity to engage with a diverse set of leading clientele from pharma, FMCG, mobility, automotive, energy and banking.</p>
<p>I recently left agency side, and launched an independent CX consultancy, <a href="https://www.linkedin.com/company/co-partnersco">Co-Partners</a> with my long time friend and business partner. We are currently consulting a VC backed SAAS scale-up, helping textile manufacturer &amp; retailer to grow its e-commerce operations and  advising an upcoming Youtube content project on sustainability.</p>
<p>My strongest data skills comes from marketing research background and long time experience on digital analytics (Hey I’m one of the first beta users of Google Analytics!) and related performance / search engine marketing disciplines.</p>
<p>My short term goal is to improve my performance in delivering data analytics related projects to my clients. Data and analytics competency is the key component for measurement, decision making, optimization and personalization in CX management.</p>
<h2 id="contact-info--social-media">Contact Info &amp; Social Media</h2>
<ul>
<li><strong>Email:</strong> <a href="mailto:kiyicim@mef.edu.tr">kiyicim@mef.edu.tr</a></li>
<li><a href="https://www.linkedin.com/in/cagataykiyici/">Linkedin</a></li>
<li><a href="https://www.linkedin.com/in/cagataykiyici/">Medium</a></li>
<li><a href="https://www.quora.com/profile/Cagatay-Kiyici">Quora</a></li>
</ul>
<h1 id="my-favorite-r-content">My Favorite R Content</h1>
<h2 id="this-weeks-video">This Week’s Video:</h2>
<p>This video from the University of Edinburgh makes things look so smooth and achievable. Bonus is the lovely Scottish accent.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/ANMuuq502rE" allowfullscreen=""></iframe>
## Highlights from  useR! 2020
### Data Journalism with R
Benedict Witzenberger from [Suddeuetche Zeitung](https://www.sueddeutsche.de/), one of the leading newspapers in Europe, made a very interesting presentation on data journalism. He is leading a team of 5 journalists with diverse backgrounds (physics, mathematics, social sciences and software development) to gather, analyze and visualize data to empower data journalism efforts. 
They heavily use R, especialy tidyverse and some specialized libraries.
 * [quanteda](https://quanteda.io/) for text mining in addition to Tidyverse standard libraries. Text mining is very useful for analyzing vast documents very quickly and create insights objectively as in political speeches or even literature analysis. It has a huge potential to deal with large and messy text document such as in leaked documents (i.e. Panama Papers).
 * A data visualization service, [DataWrapper](https://www.datawrapper.de/why-datawrapper/) is used frequently to quickly create simple graphics for digital distribution. He has created an R library, [DataWrappr](https://blog.datawrapper.de/why-i-created-an-R-library-to-use-Datawrappers-API/) to streamline data import to the tool. 
 * Data scraping from web and public resources is an important chunk of their work. For example their automated code on their server running R libraries  crawls Covid related resources and update their database every 30 minutes. 
<p>You can review their <a href="https://github.com/sueddeutsche">Github page</a> with 40 repositories. Their team can be a good resource who have practical experience on text mining, crawling, dealing with public data sets and data visualization.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/1bmdHy5vtfY" allowfullscreen=""></iframe>
## This Week's Interesting Blog Posts 
This week I browsed [Data Science Central](https://www.datasciencecentral.com/page/search?q=R) for interesting R related content. Besides tutorials and other data science content, here are my top 3 interesting R posts. 
<h3 id="easily-download-financial-data-from-yahoo-finance-"><a href="https://www.datasciencecentral.com/profiles/blogs/getting-historical-data-from-yahoo-finance-in-r">Easily Download Financial Data From Yahoo! Finance </a></h3>
<p>Simple way to download any financial data. This method can be applied in other data sources for easy web scraping. I’m sure with small additions we can automatize daily data updates and can download hundreds of different   symbols.</p>
<h3 id="is-r-shiny-versatile-enough-to-build-a-video-game"><a href="https://www.datasciencecentral.com/profiles/blogs/is-r-shiny-versatile-enough-to-build-a-video-game">Is R Shiny Versatile Enough to Build a Video Game?</a></h3>
<p>I thought Shiny is just a dashboarding tool, an alternative to Power BI or Tableau. But Shiny is very flexible and can utilize and combine front end technologies (html, css, js) for an interactive application.</p>
<h3 id="johns-hopkins-covid-19-data-and-r"><a href="https://st6.ning.com/topology/rest/1.0/file/get/4791290285?profile=original">Johns Hopkins Covid-19 Data and R</a></h3>
<p>This is 3 part series on describing how researchers at John Hopkins University handles Covid stats using R data.table package.  Great show case for hands on use of R.</p>

